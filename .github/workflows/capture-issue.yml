name: Capture Issue and Generate Post

on:
  issues:
    types: [opened, edited]

permissions:
  contents: write
  issues: read

jobs:
  capture-and-generate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          token: ${{ secrets.ADMIN_PAT }}

      - name: Check if author is authorized
        id: check_author
        env:
          ISSUE_AUTHOR: ${{ github.event.issue.user.login }}
          REPO_OWNER: ${{ github.repository_owner }}
        run: |
          # List of authorized users (comma-separated)
          # By default, only the repository owner is authorized
          AUTHORIZED_USERS="${REPO_OWNER}"
          
          # You can add more users by setting a repository secret AUTHORIZED_USERS
          # Format: "user1,user2,user3"
          if [ -n "${{ secrets.AUTHORIZED_USERS }}" ]; then
            AUTHORIZED_USERS="${{ secrets.AUTHORIZED_USERS }}"
          fi
          
          echo "Issue author: ${ISSUE_AUTHOR}"
          echo "Authorized users: ${AUTHORIZED_USERS}"
          
          # Check if author is in the authorized list
          if echo "${AUTHORIZED_USERS}" | tr ',' '\n' | grep -qx "${ISSUE_AUTHOR}"; then
            echo "âœ“ Author is authorized for AI generation"
            echo "authorized=true" >> $GITHUB_OUTPUT
          else
            echo "âœ— Author is NOT authorized for AI generation"
            echo "âš ï¸  Issue will NOT be saved to the repository to save API tokens"
            echo "âš ï¸  Only issues from authorized users are committed"
            echo "authorized=false" >> $GITHUB_OUTPUT
          fi

      - name: Save issue to file
        if: steps.check_author.outputs.authorized == 'true'
        env:
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_BODY: ${{ github.event.issue.body }}
          ISSUE_AUTHOR: ${{ github.event.issue.user.login }}
          ISSUE_CREATED_AT: ${{ github.event.issue.created_at }}
        run: |
          # Create issue directory
          mkdir -p issues
          
          # Save issue as markdown with status "pending"
          cat > "issues/issue-${ISSUE_NUMBER}.md" << 'ISSUE_EOF'
          ---
          issue_number: ${{ github.event.issue.number }}
          title: "${{ github.event.issue.title }}"
          author: ${{ github.event.issue.user.login }}
          created_at: ${{ github.event.issue.created_at }}
          status: pending
          ---

          # ${{ github.event.issue.title }}

          **Issue #${{ github.event.issue.number }}**
          **Author:** ${{ github.event.issue.user.login }}
          **Created:** ${{ github.event.issue.created_at }}

          ## Description

          ${{ github.event.issue.body }}
          ISSUE_EOF

      - name: Set up Python
        if: steps.check_author.outputs.authorized == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        if: steps.check_author.outputs.authorized == 'true'
        run: |
          pip install openai pyyaml

      - name: Generate AI post
        if: steps.check_author.outputs.authorized == 'true'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import re
          from datetime import datetime

          # Check for OpenAI API key
          openai_key = os.environ.get('OPENAI_API_KEY')
          issue_number = os.environ.get('ISSUE_NUMBER')

          if not openai_key:
              print("Warning: OPENAI_API_KEY not set. Skipping AI generation.")
              exit(0)

          # Import OpenAI
          try:
              from openai import OpenAI
              client = OpenAI(api_key=openai_key)
          except ImportError:
              print("OpenAI library not available")
              exit(1)

          # Read the issue file
          issue_file = f'issues/issue-{issue_number}.md'
          
          try:
              with open(issue_file, 'r') as f:
                  content = f.read()
          except FileNotFoundError:
              print(f"Issue file not found: {issue_file}")
              exit(1)

          # Extract metadata using YAML parsing
          import yaml
          
          # Split frontmatter from content
          if content.startswith('---'):
              parts = content.split('---', 2)
              if len(parts) >= 3:
                  try:
                      frontmatter = yaml.safe_load(parts[1])
                      title = frontmatter.get('title', 'Untitled')
                  except yaml.YAMLError:
                      # Fallback to regex if YAML parsing fails
                      match = re.search(r'title:\s*"?(.*?)"?\s*$', content, re.MULTILINE)
                      title = match.group(1) if match else 'Untitled'
              else:
                  title = 'Untitled'
          else:
              title = 'Untitled'

          print(f"Generating AI post for issue #{issue_number}: {title}")

          # LinkedIn character limit and split marker constant
          LINKEDIN_CHAR_LIMIT = 3000
          SPLIT_MARKER = '---SPLIT---'

          # Generate tech post using OpenAI
          prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“ä½œå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹ Issue å…§å®¹ï¼Œæ’°å¯«ä¸€ç¯‡çµæ§‹å®Œæ•´ã€é©åˆç™¼ä½ˆæ–¼ LinkedIn çš„ç¹é«”ä¸­æ–‡æŠ€è¡“æ–‡ç« ã€‚

          Issue å…§å®¹:
          {content}

          è«‹æ’°å¯«ä¸€ç¯‡è©³ç´°çš„æŠ€è¡“æ–‡ç« ï¼Œéœ€è¦ç¬¦åˆä»¥ä¸‹è¦æ±‚:
          1. æœ‰å¸å¼•äººçš„æ¨™é¡Œ
          2. åŒ…å«å¼•è¨€
          3. æ¸…æ¥šè§£é‡‹æŠ€è¡“å•é¡Œæˆ–ä¸»é¡Œ
          4. æä¾›è§£æ±ºæ–¹æ¡ˆã€ç¨‹å¼ç¢¼ç¯„ä¾‹æˆ–è¦‹è§£
          5. åŒ…å«çµè«–
          6. ä½¿ç”¨ Markdown æ ¼å¼
          7. **å…¨æ–‡å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«**
          8. **ä¾‹å¤–ï¼šå°ˆæœ‰åè©žï¼ˆå¦‚æŠ€è¡“è¡“èªžã€ç”¢å“åç¨±ã€ç¨‹å¼èªžè¨€åç¨±ç­‰ï¼‰å¯ä»¥ä½¿ç”¨è‹±æ–‡**
          9. **é‡è¦ï¼šLinkedIn æœ‰ {LINKEDIN_CHAR_LIMIT} å­—å…ƒé™åˆ¶ï¼Œå¦‚æžœå…§å®¹æœƒè¶…éŽæ­¤é™åˆ¶ï¼Œè«‹å°‡æ–‡ç« æ‹†åˆ†æˆå¤šç¯‡è²¼æ–‡ï¼Œæ¯ç¯‡è²¼æ–‡ä»¥ã€Œ{SPLIT_MARKER}ã€åˆ†éš”ï¼Œä¸¦åœ¨æ¯ç¯‡è²¼æ–‡é–‹é ­æ¨™è¨»ã€Œ(ç¬¬ X ç¯‡/å…± Y ç¯‡)ã€**
          10. **é‡è¦ï¼šæ¯ç¯‡æ–‡ç« çš„æœ€å¾Œä¸€è¡Œå¿…é ˆåŠ ä¸Šã€ŒðŸ¤– æœ¬æ–‡ç‚º AI ç”¢ç”Ÿçš„è²¼æ–‡ã€ä½œç‚ºè²æ˜Ž**

          è«‹ç¢ºä¿å…§å®¹å°ˆæ¥­ä¸”å…·æœ‰è³‡è¨Šåƒ¹å€¼ã€‚"""

          try:
              response = client.chat.completions.create(
                  model="gpt-4",
                  messages=[
                      {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“ä½œå®¶ï¼Œå°ˆé–€æ’°å¯«ç¹é«”ä¸­æ–‡çš„æŠ€è¡“éƒ¨è½æ ¼æ–‡ç« ã€‚å°ˆæœ‰åè©žå¯ä»¥ä½¿ç”¨è‹±æ–‡ã€‚"},
                      {"role": "user", "content": prompt}
                  ],
                  max_tokens=4000,
                  temperature=0.7
              )
              
              tech_post = response.choices[0].message.content
              
              # Split posts if they contain the split marker
              posts = tech_post.split(SPLIT_MARKER)
              posts = [p.strip() for p in posts if p.strip()]
              
              # Validate that each post part is within the LinkedIn character limit
              # If any part exceeds the limit, log a warning (AI didn't honor the limit perfectly)
              for i, post_content in enumerate(posts, 1):
                  if len(post_content) > LINKEDIN_CHAR_LIMIT:
                      print(f"Warning: Post part {i} exceeds LinkedIn limit ({len(post_content)} chars > {LINKEDIN_CHAR_LIMIT})")
              
              os.makedirs('posts', exist_ok=True)
              
              # If there are multiple posts, save each one separately
              if len(posts) > 1:
                  for i, post_content in enumerate(posts, 1):
                      post_filename = f"posts/post-{issue_number}-{datetime.now().strftime('%Y%m%d')}-part{i}.md"
                      
                      # Prepare frontmatter using YAML for proper escaping
                      frontmatter_data = {
                          'issue_number': int(issue_number),
                          'original_title': title,
                          'generated_at': datetime.now().isoformat(),
                          'status': 'generated',
                          'part': i,
                          'total_parts': len(posts)
                      }
                      
                      with open(post_filename, 'w') as f:
                          f.write("---\n")
                          f.write(yaml.dump(frontmatter_data, default_flow_style=False, allow_unicode=True))
                          f.write("---\n\n")
                          f.write(post_content)
                      
                      print(f"Generated post part {i}/{len(posts)}: {post_filename}")
              else:
                  # Single post case
                  post_filename = f"posts/post-{issue_number}-{datetime.now().strftime('%Y%m%d')}.md"
                  
                  # Prepare frontmatter using YAML for proper escaping
                  frontmatter_data = {
                      'issue_number': int(issue_number),
                      'original_title': title,
                      'generated_at': datetime.now().isoformat(),
                      'status': 'generated'
                  }
                  
                  with open(post_filename, 'w') as f:
                      f.write("---\n")
                      f.write(yaml.dump(frontmatter_data, default_flow_style=False, allow_unicode=True))
                      f.write("---\n\n")
                      f.write(tech_post)
              
                  print(f"Generated post: {post_filename}")
              
              # Update issue status - use regex to only replace in frontmatter
              updated_content = re.sub(
                  r'^status:\s*pending\s*$',
                  'status: generated',
                  content,
                  count=1,
                  flags=re.MULTILINE
              )
              with open(issue_file, 'w') as f:
                  f.write(updated_content)
              
              print("Issue status updated to 'generated'")
              
          except Exception as e:
              print(f"Error generating post: {e}")
              exit(1)
          PYTHON_SCRIPT

      - name: Commit and push changes
        if: steps.check_author.outputs.authorized == 'true'
        env:
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add issues/ posts/
          git commit -m "Add issue #${ISSUE_NUMBER} and AI-generated post: ${ISSUE_TITLE}" || echo "No changes to commit"
          
          # Push to main branch explicitly
          git push origin main
